{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba781cf-8c7f-4629-aaf6-34b4d5a43ba3",
   "metadata": {},
   "source": [
    "### Exercise 2 - Title of the Notebook\n",
    "# Tools for Data Science Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c6656-0f97-46d0-8fc3-f48f4619cdce",
   "metadata": {},
   "source": [
    "### Exercise 3 - Introduction\n",
    "\n",
    "This notebook is the final project for the data science course. It includes various exercises to demonstrate knowledge of data science tools and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def34fc-35dc-4c37-8a5c-afc615b24d17",
   "metadata": {},
   "source": [
    "### Exercise 3 - Introduction\n",
    "\n",
    "This notebook is Peer-graded Assignment for *Tools for Data Science Course*. It includes various exercises to demonstrate knowledge of data science tools and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514aeb8-393a-4242-b19a-39f19939ebed",
   "metadata": {},
   "source": [
    "### Exercise 4 - List of Data Science Languages\n",
    "Among Data Science Languages are : \n",
    "- Python\n",
    "- R\n",
    "- SQL\n",
    "- Julia\n",
    "- Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7eb1c-2161-4c7f-be94-a3df3d3241e8",
   "metadata": {},
   "source": [
    "### Exercise 5 - List of Data Science Libraries\n",
    "Among Data Science Libraries are : \n",
    "- NumPy\n",
    "- Pandas\n",
    "- Matplotlib\n",
    "- Scikit-learn\n",
    "- TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edd285-ab40-4cdc-8bb7-63b8c6d279ad",
   "metadata": {},
   "source": [
    "### Exercise 6 - Table of Data Science Tools\n",
    "\n",
    "| Category | Description | Tools |\n",
    "|----------|------------|-------|\n",
    "| Data Management | Involves collecting, storing, and retrieving data efficiently, securely, and cost-effectively. | MySQL, PostgreSQL, MongoDB, Apache CouchDB, Apache Cassandra, Hadoop File System (HDFS), Ceph |\n",
    "| Data Integration and Transformation (ETL Process) | ETL (Extract, Transform, Load) is a fundamental process that prepares raw data for analysis. | Apache Airflow, KubeFlow, Apache Kafka, Apache Nifi, Apache SparkSQL, NodeRED |\n",
    "| Data Visualization | Helps communicate insights through graphical representations, making data easier to understand for decision-makers. | Pixiedust, Hue, Kibana, Apache Superset |\n",
    "| Model Building | Involves training data with machine learning algorithms to recognize patterns and make predictions. | IBM Watson Machine Learning |\n",
    "| Model Deployment | Once trained, models must be deployed so they can deliver insights in real-world applications. | Apache PredictionIO, Seldon, MLeap, TensorFlow Serving, Kubernetes, Red Hat OpenShift |\n",
    "| Model Monitoring and Assessment | To maintain accuracy, deployed models require continuous evaluation and monitoring. | ModelDB, Prometheus, IBM AI Fairness 360, IBM Adversarial Robustness 360 Toolbox, IBM AI Explainability 360 |\n",
    "| Code Asset Management | Managing code effectively ensures version control, collaboration, and structured development. | Git, GitHub, GitLab |\n",
    "| Data Asset Management (DAM) | DAM organizes important data assets, such as images, videos, and text. | Apache Atlas, ODPi Egeria, Kylo |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21759f49-6890-439b-aa70-5ee4978cf83b",
   "metadata": {},
   "source": [
    "### Exercise 7 - Introduction to Arithmetic Expressions\n",
    "\n",
    "Arithmetic expressions are mathematical operations such as addition, subtraction, multiplication, and division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90be01b8-0f56-436c-8353-9c3eda37863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 17\n"
     ]
    }
   ],
   "source": [
    "### Exercise 8 - Multiply and Add Numbers\n",
    "x = (3 * 4) + 5\n",
    "print(\"Result:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "043f8563-d8c9-4b5f-8af8-5e0b95f5d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours: 2.0\n"
     ]
    }
   ],
   "source": [
    "### Exercise 9 - Convert Minutes to Hours\n",
    "minutes = 120\n",
    "hours = minutes / 60\n",
    "print(\"Hours:\", hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3e23c-5907-4c03-8fc8-ab32e1548532",
   "metadata": {},
   "source": [
    "### Exercise 10 - List of Objectives\n",
    "\n",
    "- Understand data science languages\n",
    "- Learn about data science libraries\n",
    "- Explore data science tools\n",
    "- Perform basic arithmetic operations in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d96a4-6124-4371-8de4-5a80aba1ee08",
   "metadata": {},
   "source": [
    "### Exercise 11 - Authorâ€™s Name\n",
    "\n",
    "Author: Santi Velantia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314d149-b4f1-4e2e-8b31-6c6ec234cde0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
